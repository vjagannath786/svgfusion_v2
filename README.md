# svgfusion_v2

# SVGFusion v2 SVGFusion v2 is an advanced pipeline for generating high-quality Scalable Vector Graphics (SVG) from text prompts. It builds upon the SVGFusion architecture and introduces modular improvements across the VAE, diffusion model, and decoder stages for more expressive and controllable vector image generation. ![SVGFusion v2 Pipeline](https://github.com/ximinng/SVGFusion/blob/master/assets/pipe.png) ## 🔧 Pipeline Overview 1. **Text Encoder (CLIP / SigLIP)** - Encodes the input prompt into a dense text embedding vector. - Used for conditioning the generative process via cross-attention or classifier-free guidance. 2. **VP-VAE (Vector-Pixel Variational Autoencoder)** - **Encoder:** Converts discrete SVG command sequences into a latent vector space. - **Decoder:** Reconstructs SVG command sequences from latent vectors, with autoregressive or residual MLP/attention blocks. 3. **Latent Diffusion Transformer (VS-DiT)** - Operates on the VP-VAE’s latent space. - Trained to denoise latent vectors, guided by the text embedding, enabling faithful text-to-SVG synthesis. - Uses a UNet-style or Transformer-style architecture for noise prediction. 4. **SVG Renderer** - Decodes output latent vectors into discrete SVG token sequences. - Converts token sequences into SVG markup. - Renders final vector image. ## ✨ Features - **Text-to-SVG Generation**: Generate high-quality vector graphics from natural language prompts. - **Latent Diffusion in Discrete Space**: Combines vector quantization and diffusion in latent space. - **Composable Architecture**: Modular design makes it easy to swap components or fine-tune specific parts. ## 🏗️ Installation ```bash git clone https://github.com/your-username/svgfusion_v2.git && cd svgfusion_v2 && pip install -r requirements.txt ``` ## 🚀 Usage ```python from inference import generate_svg prompt = "a butterfly flying over a field of flowers" svg_output = generate_svg(prompt) with open("output.svg", "w") as f: f.write(svg_output) ``` ## 🧠 Training 1. **Train VP-VAE:** ```bash python train_vpvae.py --config configs/vpvae.yaml ``` 2. **Generate Latents:** ```bash python encode_dataset.py --model vpvae --output latent_dataset.pt ``` 3. **Train Diffusion Model:** ```bash python train_vsdit.py --config configs/vsdit.yaml ``` ## 📁 Project Structure ``` svgfusion_v2/ ├── configs/ ├── models/ ├── scripts/ ├── assets/ ├── inference.py └── README.md ``` ## 🖼️ Examples | Prompt | Generated SVG | |--------|----------------| | `a blue bird sitting on a branch` | ![Example](assets/sample_bird.svg) | | `a geometric fox with sharp angles` | ![Example](assets/sample_fox.svg) | ## 📄 Citation ```bibtex @misc{xie2023svgfusion, title={SVGFusion: Vector Graphics Generation with Diffusion Models}, author={Ximin Xie and Cheng Lu and Yizhou Yu and Ying Shan and Xiaohu Qie}, year={2023}, eprint={2311.11779}, archivePrefix={arXiv}, primaryClass={cs.CV} } ``` ## 📬 Contact For issues, ideas, or contributions, feel free to open an issue or reach out!



